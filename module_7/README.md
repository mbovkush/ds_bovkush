# Project 7. Ford vs. Ferrari. Car image classification
##### Выполнила Бовкуш М.
##### Accuracy score на трейне 93.77%, на LB 93.258%. (В текущей версии на Kaggle результаты в ячейках будут немного другие, почему-то после повторного прогона цифры немного снизились - 93,43% на трейне, этот результат не субмитила)

## Цель проекта ##
Взять предобученую на ImageNet сеть Xception и дообучить под нашу задачу. 
Постараться улучшить решение, приведенное в бейзлайне, используя известные инструменты.

## Детали решения ##
1. У нас есть готовый датасет с изображениями, но количество картинок в нем недостаточное.
2. Метрика оценки качества - Accuracy.

## Требования к решению ##
1. Основным требованием к решению является применение дополнительных, не использованных в бейзлайне, инструментов.


## Что сделано ##
1. Так как в теме нейронных сетей я с нуля, то целью работы было соблюдение минимальных требований к зачету.
2. Применена аугментация данных с помощью библиотеки Albumentations.
3. Применена batch-нормализация. Для полностью обучаемой модели (без заморозки слоев) качество без BN = 92,57% (92.44 c batch_size = 32), c BN = 90,55% (10 эпох).
4. Добавлена дополнительная функция callback.
5. Применен transfer learning (произведена тонкая настройка модели). Итоговая точность 94,07%. Но графики работы на валидации странные (после 8 эпохи падает точность).
5.1. При размере батча = 32 Итоговая точность 93,77%. Не получилось повторить точность 94,07% даже при откате размера батча.
6. Применена архитектура EfficientNetB5, результат 95,15% (batch_size = 16) и 94,68 (batch_size = 32). Fine-tuning показал точность 94%. Я не смогла повторить эти результаты для сабмишена, потому что далее точность упала до 93,90%. 


## Результаты ##
+ Применение albumentations дало прирост качества, поэтому оставили этот способ аугментации.
+ Эксперимент с Fine-tuning показал прирост качества на трейне для Xception.

## Что может быть улучшено ##
+ Разобраться с методами управления LR.
+ Провести эксперименты с другими сетями.
+ Лучше разобраться с аугментацией.
+ Применить TTA.

## Ретроспектива ##
+ Проект выполнялся в условиях жестко ограниченного времени.
+ Даже судя по отзывам на другие работы, использование тех или иных методов не всегда дает наглядный результат, что затруднительно для выводов.
+ Много времени уходит на обучение моделей.
+ Остается не совсем понятным, как подбирать размер батча.
+ Непонятно, почему новые запуски обучения показывают уменьшаюшуюся точность даже при тех же параметрах, с которыми раньше они давали более точные результаты.
